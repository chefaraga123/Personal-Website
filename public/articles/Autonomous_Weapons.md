# The weapons were always autonomous

## Introduction

Autonomous weapons are a grim fixture of modern warfare, disturbing footage from drones in the Ukraine war has pushed this awareness into the popular consciousness. It would be a mistake to see the cultural backlash against autonomous weapons as purely contemporary, having been foreshadowed by films like Terminator, weapons development during the second world war and the construction of the military as a hierarchical machine. 

War is a maximally (in)human endeavour. You can take the human out of the war but you can't take the war out of the human, but that’s besides the point when you take the human out of the loop. 
Putting the ethical concerns aside, the introduction of autonomous weapons into warfare will impact the internal communications architecture of the military machine. 

Borrowing from the work of Manuel Delanda, I use the word machine to foreshadow the abstract conception of the military as an integration composed of hardware, tactics, strategy and logistics. 

To set the stage for this formulation of war as integrated machine undergirding my part 2, I'll first introduce Norbert Wiener, the prodigy who developed a weapons system we may now refer to as cybernetic, a term he coined thereafter. Subsequently, I'll explicate the role of the RAND Corporation — the organisation for the rational prosecution of war — and then discuss some of the ways in which cybernetic concepts have found their way into the Department of Defence.

In the second act I'll deploy this cybernetic ontology as a general purpose framework for understanding the evolution of the different layers in the overall stack of warfare.

There are two historical frames that I’ll use to contextualise an understanding of autonomous weapons:
- Part 1: The cybernetic origins of autonomous control in WW2 and after
- Part 2: A conceptualisation of all warfare within the framework developed in part 1
- Part 3: The implications of the contemporary trend on the architecture of the military.

---

## Part 1: Cybernetic Genesis

### The Birth of Cybernetics  
World War 2 set forth an explosion of new weapons that changed the relation of man and machine. Famous for his role working on code breaking during WW2, Alan Turing developed the  eponymous Turing test, framing what is now referred to as Artificial Intelligence.  

Not to understate the contributions of Turing, my departure point for this exploration is Norbert Wiener, who developed automatic gun targeting systems. Weiner, a child prodigy who earned his PhD at age 19 for his dissertation on mathematical logic, was an early researcher into stochastic and mathematical noise processes (**brief explanation...**).

Having done some work for the military at the end of World War One.  Under the direction of Warren Weaver Weiner, a well known mathematician at MIT, was brought into war work in 1941 on the problem of anti aircraft gunnery control. 

Weiner had worked closely with Vannevar Bush on his differential analyser (an early analog computer) who had come to head up the Office of Scientific Research and Development (OSRD), having direct control over much of the science budget during WW2. 

The problem of gun control is this - how can one accurately aim anti-aircraft guns at fast-moving enemy bomber planes? Treating the plane and the pilot as a single entity, Weiner’s approached automatic gun control as a problem of prediction under uncertainty, he built a system that took in data, processed it and hence adjusted its aim to match the aircraft’s expected future position. This was a type of negative feedback system - it continuously compared the plane’s predicted trajectory to what actually happened, using the difference to correct itself, honing in on the target with each update.

Practically, the gun control mechanism had four key components: 
- A sensor, the then recently invented radar which provided real-time data on the target’s location
- A processor, an analog computer, taking in the input from the radar and then calculating a  prediction of the future position.
- An actuator: what physically positions the gun 
- A Human operator to oversee the operation. 

While it required human approval to fire weapons, it automated the detection → decision → action chain which is the crux of the cybernetic loop. This metamorphosis from the human as executor to human as supervisor was significant for the ontology of war, something had changed radically forever.

Weiner’s major conceptual leap had been to recognise that the system formed a closed-loop feedback circuit: data was continuously processed, and used to adjust behaviour in real time - and this feedback could be automated. 

It was the result of this insight that Weiner coined the field of cybernetics as ”the science of control and communications in the animal and machine”. 

In reality the operational impact of this gun control system was modest and  the practical extent of the gun’s autonomy and the human role as supervisor was little like what we could see now. It is similar in kind. The gun control experiment was a practical example that the machine could take over routine cognitive tasks like prediction and response. 

Weiner held deep reservations about the risk of removing humans from the decision making processes, fearing that over-delegating to machines could remove moral responsibility & critical judgement. He wanted to maintain man-in-the-loop control. Paul Scharre - who helped draft DoD policy on autonomy depicts the trajectory in three ways:  
Human in the loop - direct human control 
Human on the loop - human oversight over automated systems 
Human out of the loop - full autonomy with no human intervention 

### RAND Corporation

RAND Corporation’s birth was a result of the formalisation of Operations Research during World War II.  In the 1950s RAND became the centre of System’s Analysis, 

Established in 1948, with the mandate: “a program of study and research on the broad subject of intercontinental warfare other than surface, with the objective of recommending to the Army Air Forces preferred techniques and instrumentalities for this purpose.”, the RAND Corporation became one of the home’s of cold war paranoia. 
 
RAND partially inspired Stanley Kubrick's dark comedy Doctor Strangelove or: How I learned to stop worrying and love the bomb, a film which showcased the absurdity of game theoretic approaches to war. The film portrays how,  in order to sustain the credible threat of retaliation against the United States in the event of nuclear war, the USSR creates a Doomsday device that cannot be turned off that will automatically respond to a first strike. An ironic crux of the film being how it cannot be turned off.   
The people working at RAND, a mixture of military theorists, mathematicians like von Neumann, and technocrats sought to create a new model of military rationality, one based not on heroism but on strategic logic, game theory, and theoretical models of decision-making under uncertainty.
This approach to war treated humans as functionally interchangeable components in a system, a conception of war which ontologically flattened man and machine by seeing them both in terms of feedback, communication and control. 
Seeing war as a command and control loop, lead to human decision-makers being increasingly treated like nodes in a network — agents with bounded rationality, whose behavior could be optimized, simulated, or replaced. This framing undergirded the shift towards seeing war as quantitative business, as Robert McNamara infamously did during the Vietnam War - trying to measure success in terms of linear metrics that diverged from the holistic reality. Whilst McNamara hasn’t been judged favourably by history, the integration of rationality into war through computers has only progressed.
Whilst the proto-genesis of autonomous weapons was in World War 2, during the Vietnam War Precision-Guided Munitions, such as Laser Guided Bombs were developed. This system radically improved targeting by…  
RAND Corporation’s war were wars of automata - war games became central to military planning 

Thomas Schelling, The Strategy of Conflict, is one of the most famous popularisers of the RAND school in his application of game theory to international strategy. 


## Recap

My intention with this section has been to suggest that the practical emergence of autonomous weapons began during World War Two, with Norbert Wiener’s automatic gun control project. His innovation - the closed circuit in which automatic feedback removed humans from the loop explicitly introduced the possibility of machines performing end-2-end tasks.

This, combined with the intellectual development of game theory, metamorphosed war into a rational system in which people - as predictable agents - were interchangeable with machines - a world in which the distinction between autonomous weapons and “subordinated” weapons is dissolved. 

The RAND Corporation, and the military industrial complex drove this trend, further institutionalising this new military epistemology.In section two, I argue that the logic of automation has always been embedded in military thought, modern, or at least post-world war two weapons merely represent an acceleration of existing tendencies.

---
## Part 2: Cybernetic Ontology

Now that we’ve developed the framework to understand the institutionalisation of autonomous weapons we can now think about how the drive towards rational war is central to the history of warfare as a whole.  

### Autonomous Tactics 
Tactical units are information processors, they follow a decision loop: they observe their environment, analyse the situation, decide the course of action and then execute on it. 

Tactical units are given instructions they have to execute - either through precise instructions that flow from the top or just a high-level goal (what is known as mission-type tactics) where the what is defined by command but the how is left to the unit’s discretion. 

The relationship between tactics and strategy has changed over time, as the increased complexity of the battlefield driven by novel weaponry has pushed decision-making downward - towards smaller tactical units. If all decision making was channelled through top-command in the modern battlefield the top would become overwhelmed. This decentralisation stepped up during the later stages of WW1 when the stalemate demanded a new approach. 

Highly centralised systems may be characterised by long feedback loops, single points of failure, and top-down command and control, while highly decentralised systems may be characterised by short feedback loops, multiple points of failure - or redundancy, and bottom-up decision making.
 
A story of this military machine can be told in terms of varying degrees of centralisation and decentralisation, characteristics of systems and the level of autonomy of the different components. 

### Autonomous Weapons 

Autonomous weapons take this farther - the unification of hardware with tactics - as the tactics are abstracted and embedded in the hardware. 

More generally, an autonomous weapon can be understood as a piece of hardware which displaces human judgement from the decision-making loop, as we saw with Norbert Wiener's automatic gun control system, or introduce feedback loops where none existed such as with the laser-guided bombs in the Vietnam War. Whilst these systems didn’t eliminate human involvement they redistributed agency. 

Autonomous weapons are only a part of the wider military machine - they still rely on a supply chain and are only deployed given a particular strategy. Autonomous weapons may even directly work together with humans. To speak of autonomous weapons as an essential type that exists is difficult. . 

From the perspective of command, autonomous weapons lie within the pattern of mission-type tactics that has become predominant.

Autonomous weapons remove command from the decision making loop - but is that fundamentally different to the platoons which have their local loop. From the perspective of command, an autonomous weapon is any entity that sets its own implementation. Autonomous weapons are only an epistemic novelty because of how they make explicit the implicit logic of decentralisation that has long existed in modern warfar.e 

Do autonomous weapons tend towards centralisation or decentralisation?


### Clockwork Armies 
Automata - not autonomy 
The Turk was a fake chess-playing automaton built in 1770 by Wolfgang von Kempelen, to those not in the know The Turk appeared to be a mechanical figure capable of playing - and often winning - complex games against human opponents. 19th century sources claim that The Turk played, and defeated, Frederick the Great, the Monarch that transformed Prussia into a major European power, whilst those claims are most likely apocryphal, it is true that as a hobby he loved to collect mechanical birds, and clockwork devices. These toys were a microcosm of Frederick’s approach to war, as he fashioned his armies after clockwork automata. 

Philosopher Manuel De Landas labels his armies clockwork. A clockwork army is characterised by a one-way flow of information, and an external source of energy. 
The army’s brain is responsible for practically all decision making. 
Although this is a step in that direction as the routinization of the 

Foreshadowing Frederick Taylor’s Taylorism, aka Scientific Management and its time tests, Frederick II’s armies were subject to a similar logic. Drills were broken down into granular steps permitting a tactical calculus. 

Frederick’s soldiers were proscribed from individual initiative - there were pro-automata; their only role was to cooperate in the creation of walls of projectiles through synchronised firepower.  

### Platoons (second)
The pressure of the increased accuracy and range of firearms forced tactical decision makers to adapt 

contemporary platoons in which small tight-knit squads have significant autonomy without the need to relay the information they receive back to central command. 

WW1 - German Stormtroopers 

### The Blitzkrieg
The blitzkrieg is one of, if not the, most well known military strategy executed during WW2. It is widely understood as the rapid 

German tanks and planes, in contrast with their allied counterparts, were equipped with two-way communication capabilities. This allowed commanders and units on the ground to coordinate and respond dynamically to changing conditions without waiting for centralised orders. 

This technological advantage was wrapped up by the German military concept of Auftragstaktik - or mission-type tactics. This foreshadowed the types of distributed control that are obvious in the case of drone swarms.

This shift from purely vertical flows in communication shifted to lateral flows. 

Rather than saying how to execute a maneuver, units were provided with an objective and they were given the autonomy to achieve that objective.

This tactical doctrine had an OODA loop advantage, was more flexible under uncertainty / less brittle when plans were subverted by unexpected events. 

Part of German strategy was localisation of the decision making, an artifact we see in 



## Part 3: What this means for how we think about autonomous weapons contemporarily


## Sources 

### Light summaries of my sources
- **[Pieces of the Action by Vannevar Bush](../books/Pieces_of_the_Action)**
- **[War in the Age of Intelligent Machines by Manuel De Landa](../books/War_in_the_Age_of_Intelligent_Machines)**
- **[Machine Dreams: Economics as a Cyborg Science by Phil Mirowski](../books/Machine_Dreams)**
- **[In Retrospect by Robert McNamara](../books/Retrospect)**
